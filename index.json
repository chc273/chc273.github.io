[{"content":"The 2022 ChatGPT Moment When ChatGPT was announced at the end of 2022, I spent hours talking to it, genuinely amazed at how it was a step up compared to the previous GPT-3 models (davinci, curie, if those ring a bell). Around that time, I had been on-and-off playing with LangChain to build tool-using agents. While the agents felt unreliable, they made for great demo-ware. The pace of innovation was staggering. The LangChain team shipped new features in a matter of hours, a sign that the AI space was heating up fast.\nFor the next few weeks, I was playing with ChatGPT almost non-stop, with mixed feelings. Hallucination was real, and it was really hard to get the 3.5-turbo models to follow instructions reliably. It constantly made up wrong citations and could not do simple math. Even GPT-4 could not count the number of letters in a word.\nBuilding Copilot for Chemistry At the time, I was working on Azure Quantum Elements, which aimed to bring together HPC, AI, and quantum computing for scientific discovery. We had data and models for molecules and materials, so it was natural to try LangChain\u0026rsquo;s ReAct agent for coordinating the execution of those tools. The agent worked well when the problem space and user\u0026rsquo;s questions matched the narrow fields it was designed for.\nBased on the demo\u0026rsquo;s promise, we realized this seemed to be the future. We rallied a team to intensely work on developing Copilot in Azure Quantum for chemistry and materials. Around the same time, the ChemCrow (Bran et al., 2023) paper came out, and the results gave us a lot of confidence.\nWe announced Azure Quantum Elements and the Copilot in June 2023 (Zander, 2023). It was a really fun time when a small group of us worked day and night, including weekends for months to make that happen, navigating the responsible AI process along the way. Nobody was asked to work overtime, but everyone was always online to deploy, test, and fix things fast.\nLooking back, we had a few good ideas that were probably ahead of their time. We had a rendering window for molecules and calculation results. Later people invented a new term for this UX, namely \u0026ldquo;Generative UI.\u0026rdquo; In the scientific field, we deal with big data objects in addition to text responses. Passing large calculation data was nontrivial, and we invented a new way to do that given the limited context of language models.\nWorkflow vs Agent In an ideal world, I envisioned that the service would evolve into what we now call an \u0026ldquo;AI Scientist.\u0026rdquo; The reality is like many early AI services: the churn rate was high. It was reasonably popular for some time, then user engagement dropped and it no longer made sense to maintain. To this date, the only thing I could quickly find was in this blog post (Chen \u0026amp; Almulla, 2023). AI (even with GPT-4, the best model at the time) was still not great at understanding human instructions, and the system was not very reliable, as people reported edge cases all the time. We tried to automate the tests, but the APIs were slow and those are more like regression tests, instead of trying to predict what new queries users may come up with. Again, if we were to build it today, the development of LLM evaluation field and automated red teaming would help us solve some of those.\nThis made us wonder if a workflow-based system would make more sense. The LangChain blog had a nice analysis on this topic (Chase, 2025).\nObviously, people in the AI space realized this earlier than we did, and LangGraph was developed to address these reliability concerns using more deterministic execution graphs (perhaps also fixing the confusing interface from LangChain). The concept of agentic workflows was later integrated into Microsoft\u0026rsquo;s Agentic Framework, after a few branding iterations and mergers with other tools like Semantic Kernel, AutoGen, etc. (Microsoft, 2025).\nThe Reasoning Revolution Beyond the reliability issues, we also realized something deeper was missing. A scientific process (or arguably any complex task) requires more than a chatbot. They require more of \u0026ldquo;System 2\u0026rdquo; thinking (slow/deliberate/reflective processes) than \u0026ldquo;System 1\u0026rdquo; thinking (fast/automatic/intuitive processes) (Kahneman, 2011).\nThe famous Chain-of-Thought paper (Wei et al., 2022) was groundbreaking, albeit simple. By eliciting reasoning steps, language models like ChatGPT were able to achieve better results, mimicking how humans work. Then there were several very interesting prompting techniques. Something I recall trying with a colleague was adding \u0026ldquo;take a deep breath\u0026rdquo; from DeepMind (Yang et al., 2023). It\u0026rsquo;s funny, but in some cases it worked.\nThe o-series reasoning models from OpenAI made a splash. They pioneered test-time compute and extended the chain-of-thought idea by spending more tokens to achieve much better results. This unlocked so many doors and was perhaps a key moment for AI in scientific discovery.\nI was switching between ChatGPT, Gemini, and Claude around that time. Then Deep Research from both Gemini and ChatGPT really won me over as a user, and Claude was just in its own league for software engineering tasks. I ended up paying for all of them to this day. It seemed inches away to connect deep research with automated software engineering for autonomous research engineering work.\nThe Rise of AI Scientists and the Return of Agents While many teams were looking into deterministic workflows due to reliability concerns, the rapid improvements in reasoning capabilities quietly made fully autonomous agents viable again. While Microsoft was pitching the concept of \u0026ldquo;Copilot\u0026rdquo;, a related concept of \u0026ldquo;AI (co-)Scientist\u0026rdquo; took off. It started with Gomes\u0026rsquo; team publishing their results on Coscientist in (Boiko et al., 2023). Later, Google shared their AI co-Scientist (Gottweis et al., 2025), and fast forward to recent news where FutureHouse released Kosmos after a few product iterations (Mitchener et al., 2025).\nThe fundamental idea is surprisingly simple. In some way, it is running reasoning and tool calling in a loop. Lilian Weng\u0026rsquo;s blog (Weng, 2023) is a great resource on the high-level concepts. But of course, building a reliable one is extremely hard, something we faced every day during the Copilot development.\nWith frontier AI labs pushing intelligence forward, the distinction between workflows and AI agents becomes blurrier. I personally found, particularly in the last few months, that agentic systems can achieve fairly reliable execution while being more flexible across many tasks. I started to truly feel that we are entering the agentic era from the chatbot generative AI era. Jensen Huang was definitely right on this.\nThe Copilot for Chemistry initiative was not completely lost. Earlier this year, Microsoft Discovery (Microsoft, 2025) was announced, pushing to build an agentic platform for science. My previous work on AI-accelerated battery electrolyte discovery (Chen et al., 2024) was used as an example of how AI can help accelerate scientific discovery. AI brings unique value to science.\nWhat\u0026rsquo;s Next? One big trend in 2025 was seeing startups in AI for materials science or physical AI companies with a heavy component in materials raising big funding rounds, again reiterating Jensen\u0026rsquo;s vision about the future of physical AI. The Genesis Mission executive order (The White House, 2025) pushes the heat to another level. It all makes a lot of sense, as materials and engineering serve as the building blocks for our society. From my past work in this space, it was very clear to me that AI is going to help discover a lot of materials, and it is only a matter of execution, validation, and scale. Perhaps this by itself will be another blog post at a later stage.\nThe data question is becoming central: the whole internet\u0026rsquo;s data is somewhat exhausted, so you would need to generate synthetic data or experimental data. Lots of experiments in science, if you capture all the data, can be extremely valuable if one knows how to merge that data with existing data and figure out a path towards scientific superintelligence.\nThis is likely where quantum computing enters the picture. As I work in the quantum computing industry, I see a natural connection: materials and molecules fundamentally operate on quantum mechanics principles, which classical computers struggle to simulate accurately. Quantum computers could generate training data that captures physics classical systems cannot, potentially unlocking new frontiers for AI in science. 2026 is going to be another exciting year for AI for Science.\nWhat I Learned If I had to summarize what the past few years taught me:\nWe kept hitting reliability problems, not capability problems. The demos were always impressive, but getting things to work in production was a different story. Users found edge cases we never thought of, and maintenance became a full-time job that few want to take.\nThe reasoning models (o1, o3) were the unlock. Before that, we were patching unreliable systems with workflows. After that, agents actually started working.\nWe went from agents to workflows and back to agents. It felt like going in circles, but the second time around, the agents were better. Sometimes you have to retreat before you can advance.\nAnd now everyone is talking about data. The internet is tapped out. Science has data that nobody else has, and that might be the edge. The nice part about science is that you can validate in real world.\nFinal Words I have long hoped to build an agent that can automate myself. Deep Research was probably the first tool that I felt was powerful enough to replace part of myself for literature review and information gathering. The barrier to entering a new field has never been lower. During the break, I decided to build an agent for writing research review articles for me. The following is a 148-page zero-shot generation (plus answering the clarification questions) of my \u0026ldquo;literature-reviewer\u0026rdquo; agent using the prompt \u0026ldquo;Impacts and potentials of quantum computing for artificial intelligence\u0026rdquo;.\nIf you\u0026rsquo;re curious about how quantum computing can help build better AI, take a look:\nImpacts and Potentials of Quantum Computing for Artificial Intelligence: A Comprehensive Review\nIt is not perfect, but it is a fitting way to close 2025. A year where the tools we dreamed of building finally started building themselves.\nReferences 1. Bran, A., Cox, S., Schilter, O., Baldassari, C., White, A. \u0026amp; Schwaller, P. (2023). ChemCrow: Augmenting large-language models with chemistry tools. arXiv preprint. https://doi.org/10.48550/arXiv.2304.05376 2. Boiko, D., MacKnight, R., Kline, B. \u0026amp; Gomes, G. (2023). Autonomous chemical research with large language models. Nature, 624, 570-578. https://doi.org/10.1038/s41586-023-06792-0 3. Gottweis, J., Weng, W., Daryin, A., Tu, T., Palepu, A. \u0026amp; et al. (2025). Towards an AI co-scientist. arXiv preprint. https://doi.org/10.48550/arXiv.2502.18864 4. Mitchener, L., Yiu, A., Chang, B., Bourdenx, M. \u0026amp; et al. (2025). Kosmos: An AI Scientist for Autonomous Discovery. arXiv preprint. FutureHouse. https://doi.org/10.48550/arXiv.2511.02824 5. Weng, L. (2023). LLM Powered Autonomous Agents. https://lilianweng.github.io/posts/2023-06-23-agent/ 6. Chen, C. \u0026amp; Almulla, Y. (2023). Increasing research and development productivity with Copilot in Azure Quantum Elements. https://azure.microsoft.com/en-us/blog/quantum/2023/12/12/increasing-research-and-development-productivity-with-copilot-in-azure-quantum-elements/ 7. Microsoft (2025). Transforming R\u0026amp;D with agentic AI: Introducing Microsoft Discovery. https://azure.microsoft.com/en-us/blog/transforming-rd-with-agentic-ai-introducing-microsoft-discovery/ 8. Chase, H. (2025). How to Think About Agent Frameworks. https://blog.langchain.com/how-to-think-about-agent-frameworks/ 9. Microsoft (2025). Agent Framework Workflow Overview. https://learn.microsoft.com/en-us/agent-framework/user-guide/workflows/overview 10. Yang, C., Wang, X., Lu, Y., Liu, H., Le, Q., Zhou, D. \u0026amp; Chen, X. (2023). Large Language Models as Optimizers. arXiv preprint. https://doi.org/10.48550/arXiv.2309.03409 11. Kahneman, D. (2011). Thinking, Fast and Slow. New York, NY: Farrar, Straus and Giroux. ISBN: 9780374275631. 12. Wei, J., Shazeer, N., Gaussier, E. \u0026amp; Brown, Q. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models. Advances in Neural Information Processing Systems, 35. https://doi.org/10.48550/arXiv.2201.11903 13. Chen, C., Nguyen, D., Lee, S., Baker, N., Karakoti, A., Lauw, L., Owen, C., Mueller, K., Bilodeau, B., Murugesan, V. \u0026amp; Troyer, M. (2024). Accelerating Computational Materials Discovery with Machine Learning and Cloud High-Performance Computing: from Large-Scale Screening to Experimental Validation. Journal of the American Chemical Society, 146, 20009-20018. American Chemical Society. https://doi.org/10.1021/jacs.4c04074 14. The White House (2025). Launching the Genesis Mission. https://www.whitehouse.gov/presidential-actions/2025/11/launching-the-genesis-mission/ 15. Zander, J. (2023). Accelerating scientific discovery with Azure Quantum. https://blogs.microsoft.com/blog/2023/06/21/accelerating-scientific-discovery-with-azure-quantum/ ","permalink":"https://cchen.me/posts/2025-12-23-ai-reflection/","summary":"\u003ch2 id=\"the-2022-chatgpt-moment\"\u003eThe 2022 ChatGPT Moment\u003c/h2\u003e\n\u003cp\u003eWhen ChatGPT was announced at the end of 2022, I spent hours talking to it, genuinely amazed at how it was a step up compared to the previous GPT-3 models (davinci, curie, if those ring a bell). Around that time, I had been on-and-off playing with \u003ca href=\"https://www.langchain.com/\" target=\"_blank\" rel=\"noopener\"\u003eLangChain\u003c/a\u003e to build tool-using agents. While the agents felt unreliable, they made for great demo-ware. The pace of innovation was staggering. The LangChain team shipped new features in a matter of hours, a sign that the AI space was heating up fast.\u003c/p\u003e","title":"2025 Reflection on AI and Agents"}]